{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.ddx_data_gen.json_extraction import load_schemes_and_labelspace\n",
    "from src.ddx_data_gen.prompt_args import PromptArgs\n",
    "from src.eval.pipeline import extract_json_and_pred_from_text\n",
    "from src.utils import init_notebook, convert_codes_to_short_codes, load_sbert_model\n",
    "from src.wandb.data_loader import load_cross_validation_patients\n",
    "from src.wandb.run import init_wandb\n",
    "from src.exp_args import ExpArgs\n",
    "\n",
    "init_notebook()\n",
    "\n",
    "from src.eval.classification_metrics import (calculate_icd_metrics, calculate_disease_metrics,\n",
    "                                             get_valid_json_pct, summarize_cv_results,\n",
    "                                             calculate_in_domain_score)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wandb_run = init_wandb('Evaluation', eval_mode=True)\n",
    "# all_dfs = {}\n",
    "\n",
    "prompt_args = PromptArgs()\n",
    "ood_prompt_args = PromptArgs()\n",
    "exp_args = ExpArgs()\n",
    "test_patients = pd.read_parquet('data/reasoning/abdominal_pain/test_dataset.pq')\n",
    "ood_patients = pd.read_parquet('data/reasoning/patients_ood_700.pq')\n",
    "load_schemes_and_labelspace(test_patients, prompt_args, exp_args)\n",
    "load_schemes_and_labelspace(ood_patients, ood_prompt_args, exp_args)\n",
    "mapping_model = load_sbert_model()"
   ],
   "id": "97b310491942fae2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_model = \"eval_results_Qwen3-0.6B\"\n",
    "names_06 = {\n",
    "    f\"{base_model}\" : f\"{base_model}-think-cc64\",\n",
    "    f\"{base_model}-G\" : f\"{base_model}-think-guid_decoding-cc64\",\n",
    "    f\"{base_model}-Mimic\" : f\"{base_model}-lora-1mimic-think-cc64\",\n",
    "    f\"{base_model}-Mimic-G\" : f\"{base_model}-lora-1mimic-guid_decoding-cc64\",\n",
    "    f\"{base_model}-Lora\" : f\"{base_model}-lora-1epoch-think-cc64\",\n",
    "    f\"{base_model}-Lora-G\" : f\"{base_model}-lora-1epoch-think-guid_decoding-cc64\",\n",
    "    f\"{base_model}-2Mimic\" : f\"{base_model}-lora-2mimic-cc64\",\n",
    "    f\"{base_model}-2Mimic-G\" : f\"{base_model}-lora-2mimic-guid_decoding-cc64\",\n",
    "    f\"{base_model}-2Lora\" : f\"{base_model}-lora-2epoch-cc32\",\n",
    "    f\"{base_model}-2Lora-G\" : f\"{base_model}-lora-2epoch-guid_decoding-cc64\",\n",
    "}\n",
    "\n",
    "base_model = \"eval_results_Qwen3-8B\"\n",
    "names_8 = {\n",
    "    f\"{base_model}\" : f\"{base_model}-think-cc32\",  # Works!\n",
    "    f\"{base_model}-G\" : f\"{base_model}-think-guid_decoding-cc32\",  # Works!\n",
    "    f\"{base_model}-Mimic\" : f\"{base_model}-lora-1mimic-cc32\",  # Works!\n",
    "    f\"{base_model}-Mimic-G\" : f\"{base_model}-lora-1mimic-guid_decoding-cc32\",  # Works!\n",
    "    f\"{base_model}-Lora\" : f\"{base_model}-lora-1epoch-cc32\",\n",
    "    f\"{base_model}-Lora-G\" : f\"{base_model}-lora-1epoch-guid_decoding-cc32\", # Works!\n",
    "    f\"{base_model}-2mimic\" : f\"{base_model}-lora-2mimic-cc32\",  # Works!\n",
    "    f\"{base_model}-2mimic-G\" : f\"{base_model}-lora-2mimic-guid_decoding-cc32\",  # Works!\n",
    "    f\"{base_model}-2-Lora\" : f\"{base_model}-lora-2epoch-cc32\",  # Works!\n",
    "    f\"{base_model}-2-Lora-G\" : f\"{base_model}-lora-2epoch-guid_decoding-cc64\",  # Works!\n",
    "}\n",
    "base_model = \"eval_results_Qwen3-14B\"\n",
    "names_14 = {\n",
    "    f\"{base_model}\" : [f\"{base_model}-cc32\", f\"{base_model}-think-cc32\"],  # Works!\n",
    "    f\"{base_model}-G\" : f\"{base_model}-guid_decoding-cc32\",  # Works!\n",
    "    f\"{base_model}-Lora\" : [f\"{base_model}-lora-1epoch-cc32\", f\"{base_model}-lora-1epoch-think-cc32\"],\n",
    "    f\"{base_model}-Lora-G\" : f\"{base_model}-lora-1epoch-guid_decoding-cc32\",\n",
    "    f\"{base_model}-2Lora\" : f\"{base_model}-lora--2lora-cc32\",\n",
    "    f\"{base_model}-2Lora-G\" : f\"{base_model}-lora--2lora-think-guid_decoding-cc32\",  # Wrong name. Run no thinking\n",
    "    f\"{base_model}-3Lora\" : f\"{base_model}-lora-3epoch-think-cc32\",\n",
    "    f\"{base_model}-3Lora-G\" : f\"{base_model}-lora-3epoch-guid_decoding-cc32\",  \n",
    "}\n",
    "base_model = \"eval_results_Qwen3-32B\"\n",
    "names_32 = {\n",
    "    f\"{base_model}\" : f\"{base_model}-cc32\",  # Works!\n",
    "    f\"{base_model}-G\" : f\"{base_model}-guid_decoding-cc16\",  # Works!\n",
    "    f\"{base_model}-Lora\" : f\"{base_model}-lora-1epoch-think-cc32\",\n",
    "    f\"{base_model}-Lora-G\" : f\"{base_model}-lora-1epoch-guid_decoding-cc32\",\n",
    "    f\"{base_model}-2Lora\" : [f\"{base_model}-lora-2epoch-cc32\", f\"{base_model}-lora-2epoch-cc64\"],\n",
    "    f\"{base_model}-2Lora-G\" : f\"{base_model}-lora-2epoch-guid_decoding-cc64\",\n",
    "}\n",
    "\n",
    "other_base_models = {\n",
    "    \"MedReason-8B\": \"eval_results_MedReason-8B-cc32\",\n",
    "    \"MedReason-8B-G\": \"eval_results_MedReason-8B-guid_decoding-cc32\",\n",
    "    \"Medgemma-27b\": \"eval_results_medgemma-27b-text-it-cc32\",\n",
    "    \"Medgemma-27b-G\": [\"eval_results_medgemma-27b-text-it-guid_decoding-cc16\", \"eval_results_medgemma-27b-text-it-guid_decoding-cc32\"],\n",
    "    \"Llama-3.3-70B\": \"eval_results_Llama-3.3-70B-Instruct-cc16\",\n",
    "    \"Llama-3.3-70B-G\": \"eval_results_Llama-3.3-70B-Instruct-guid_decoding-cc32\",\n",
    "}\n",
    "base_model = \"eval_results_Qwen3-8B-OOD\"\n",
    "ood_models = {\n",
    "    \"Qwen3-8B-OOD\": f\"{base_model}-cc32\",\n",
    "    \"Qwen3-8B-OOD-G\": [f\"{base_model}-guid_decoding-cc32\", f\"{base_model}-guid_decoding-cc32\"],\n",
    "    \"Qwen3-8B-OOD-Mimic\": f\"{base_model}-lora-1mimic-cc32\",\n",
    "    \"Qwen3-8B-OOD-Mimic-G\": f\"{base_model}-lora-1mimic-guid_decoding-cc32\",\n",
    "    \"Qwen3-8B-OOD-Lora\": f\"{base_model}-lora-1epoch-cc32\",\n",
    "    \"Qwen3-8B-OOD-Lora-G\": f\"{base_model}-lora-1epoch-guid_decoding-cc32\",\n",
    "    \"Qwen3-8B-OOD-2Mimic\": f\"{base_model}-lora-2mimic-cc32\",\n",
    "    \"Qwen3-8B-OOD-2Mimic-G\": f\"{base_model}-lora-2mimic-guid_decoding-cc32\",\n",
    "    \"Qwen3-8B-OOD-2Lora\": f\"{base_model}-lora-2epoch-cc32\",\n",
    "    \"Qwen3-8B-OOD-2Lora-G\": f\"{base_model}-lora-2epoch-guid_decoding-cc32\",\n",
    "}"
   ],
   "id": "f450d0472d30862b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(3):\n",
    "    df = all_dfs['eval_results_Qwen3-8B'][i]\n",
    "    df.to_parquet(f'data/results/qwen3_8b/base/qwen3_8b_base_{i}.pq')"
   ],
   "id": "124ed09fe3f5fed5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, file in ood_models.items():\n",
    "    if len(all_dfs.get(name, [])) >= 3:  # FixMe Ensure 3 of all that royu want to report\n",
    "        print(f'Skip {name} already downloaded')\n",
    "        continue\n",
    "    try:\n",
    "        dfs = load_cross_validation_patients(wandb_run, file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    for df in dfs:\n",
    "        if 'OOD' not in name:\n",
    "            df['Chief Complaint'] = 'abdominal_pain'\n",
    "            extract_json_and_pred_from_text(df, prompt_args, mapping_model)\n",
    "        else:\n",
    "            extract_json_and_pred_from_text(df, ood_prompt_args, mapping_model)\n",
    "            \n",
    "        \n",
    "    all_dfs[name] = dfs"
   ],
   "id": "4f979b433a472f57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cosine_similarity_torch(prediction, label, scale_to_unit=True):\n",
    "    # Convert to tensors on the correct device\n",
    "    prediction = tensor(prediction, dtype=torch.float32, device='mps')\n",
    "    label = tensor(label, dtype=torch.float32, device='mps')\n",
    "\n",
    "    # Compute cosine similarity along the last dimension (vector dimension)\n",
    "    cos_sim = F.cosine_similarity(prediction, label, dim=1)\n",
    "\n",
    "    # Optionally scale from [-1, 1] to [0, 1]\n",
    "    if scale_to_unit:\n",
    "        cos_sim = (cos_sim + 1) / 2\n",
    "\n",
    "    return cos_sim.mean().item()\n",
    "\n",
    "\n",
    "def calculate_metrics(df: pd.DataFrame, generation=False) -> dict:\n",
    "\n",
    "    metrics = {}\n",
    "    if generation:\n",
    "        metrics['old_V1'] = df['v1_score'].mean()\n",
    "        v1_preds = df['v1_preds'].map(ast.literal_eval).to_list()\n",
    "        v1_labels = df['disease_vector'].to_list()\n",
    "        metrics['V1_CosSim'] = cosine_similarity_torch(v1_preds, v1_labels)\n",
    "    \n",
    "    metrics['V2_MRR'] = calculate_disease_metrics(df['v2_preds'], df['disease'])\n",
    "    if generation:\n",
    "        metrics['V3_VRR'] = calculate_disease_metrics(df['v3_preds'], df['disease'])\n",
    "\n",
    "    v4_labels = df['ICD_CODES'].map(convert_codes_to_short_codes).to_list()\n",
    "    metrics.update(calculate_icd_metrics(df['v4_preds'].to_list(), v4_labels))\n",
    "    metrics.update({'Valid JSON': get_valid_json_pct(df)})\n",
    "    # metrics.update({'In Domain ICDs': calculate_in_domain_score(df)})\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_mean_metrics(experiments: dict, data: dict, std=False) -> pd.DataFrame:\n",
    "    experiment_results = pd.DataFrame()\n",
    "    experiments = [experiment for experiment in experiments if experiment in data.keys()]\n",
    "    # labels = data[experiments[0]][0]['ICD_CODES'].map(convert_codes_to_short_codes).to_list()\n",
    "    for experiment_name in experiments:\n",
    "        results = []\n",
    "        for df in data[experiment_name]:\n",
    "            metrics = {}\n",
    "            metrics.update(calculate_metrics(df))\n",
    "            results.append(metrics)\n",
    "    \n",
    "        experiment_results = pd.concat([experiment_results, summarize_cv_results(results, experiment_name, std)], axis=0)\n",
    "        \n",
    "    return experiment_results.round(3)"
   ],
   "id": "31952c1ddf4a5805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_mean_metrics(other_base_models, all_dfs, True)",
   "id": "153872138c0e8dc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_mean_metrics(ood_models, all_dfs, True)",
   "id": "16c323573b7eccaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_mean_metrics(names_06, all_dfs, True)",
   "id": "785a79835b29de59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_mean_metrics(names_8, all_dfs, True)",
   "id": "116a1a35b7c13f89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_mean_metrics(names_14, all_dfs, True)",
   "id": "4c0f4a091d4b574c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_mean_metrics(names_32, all_dfs, True)",
   "id": "49d689ddc94e17a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gen_dfs = {\n",
    "    'Qwen3-32B': pd.read_parquet('data/results/generation/dataset_3055_qwen3_32b.pq'),\n",
    "    'Llama-3.3-70B': pd.read_parquet('data/results/generation/dataset_3055_Llama_3.3_70B_Instruct.pq'),\n",
    "    'Medgemma-27b': pd.read_parquet('data/results/generation/dataset_3055_medgemma_27b_text_it.pq'),\n",
    "}\n",
    "gen_prompt_args = PromptArgs()\n",
    "load_schemes_and_labelspace(gen_dfs['Qwen3-32B'], gen_prompt_args, exp_args)\n",
    "\n",
    "for name, df in gen_dfs.items():\n",
    "    df['Chief Complaint'] = 'abdominal_pain' \n",
    "    extract_json_and_pred_from_text(df, gen_prompt_args, mapping_model, True)\n"
   ],
   "id": "d7941f7e3f192a41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gen_metrics = {}\n",
    "for name, df in gen_dfs.items():\n",
    "    gen_metrics[name] = calculate_metrics(df, True)\n",
    "pd.DataFrame(gen_metrics).T.round(3)"
   ],
   "id": "32b2ad43afa75faa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gen_metrics = {}\n",
    "for name, df in gen_dfs.items():\n",
    "    gen_metrics[name] = calculate_metrics(df, True)\n",
    "pd.DataFrame(gen_metrics).T.round(4)"
   ],
   "id": "1ea84b7fe40c07e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f9ef42b34b4ba2c5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
