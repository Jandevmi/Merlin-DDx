name: refactor-test  # If lora on last 6 chars will be used in wandb name
server_image: registry.datexis.com/jfrick/vllm_server:nightly
client_image: registry.datexis.com/jfrick/vllm_client:latest
namespace: clinibench
load_from_checkpoint: False
Hardware:
  client_gpu: "p100"
  server_gpu: "b200"
  parallel_size: 2
Model:
  base_model: "Qwen/Qwen3-8B"
  max_model_len: 8192
  max_num_seqs: 1024
  max_num_batched_tokens: 131072  # 131072 32768 65536 131072
  dtype: "auto"
  thinking: False
  lora: False
  lora_modules: "qwen3-8b-sft-all-vall/checkpoint-1608"
  max_lora_rank: 128
Client_Job:
  num_choices: 4 # Set to 1 if guided decoding is applied
  num_samples: 10
  concurrency: 32
  batch_size: 1
  start_verifier: 1
  budget: [4, 4, 4, 5]
  temperatures: [0.4, 0.4, 0.4, 0.4] # Set to 0 if guided decoding is applied
  max_tokens: [1500, 1300, 1500, 1800]
  thresholds: [0.0, 0.0, 0.0, 0.0]
  eval_mode: True
  ood_eval: False
  merlin_mode: False
  think_about_labs: True
  guided_decoding: True
  store_patients: True
